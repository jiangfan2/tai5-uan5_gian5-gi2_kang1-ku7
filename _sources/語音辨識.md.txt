# 語音辨識（Speech Recognition）
語音辨識就是共語音轉做文字，
會當用佇語音指令佮問答系統（親像蘋果公司的Siri）。

這方面的開源工具有`Kaldi`佮`HTK`

## Kaldi
[github](https://github.com/kaldi-asr/kaldi)佮[官方文件](http://kaldi-asr.org/doc/)。
目前包[匯出Kaldi格式資料](https://github.com/sih4sing5hong5/tai5-uan5_gian5-gi2_hok8-bu7/blob/master/%E8%87%BA%E7%81%A3%E8%A8%80%E8%AA%9E%E6%9C%8D%E5%8B%99/management/commands/%E5%8C%AF%E5%87%BAKaldi%E6%A0%BC%E5%BC%8F%E8%B3%87%E6%96%99.py)佮[taiwanese](https://github.com/sih4sing5hong5/kaldi/tree/taiwanese/egs/taiwanese/s5c)訓練script。

### 入手
1. 需Unix，建議使用[Mint Linux](https://www.linuxmint.com/download.php)作業系統。若是Mac需要先走`brew install automake autoconf wget libtool`
2. [裝kaldi](http://kaldi-asr.org/doc/install.html)
	1. 入去`tools` ，而且照`INSTALL`做
	2. 入去`src` ，而且照`INSTALL`做
3. 走範例
	1. 入去`egs/yesno/s5`，照伊的`README`指示
		- `bash run.sh`，幾分鐘內程式會走了
	2. 入去`egs/vystadial_en/s5`，照伊的`README`指示
		- 照家己的需要改`cmd.sh`
		- `bash run.sh`
			- CPU時間需要5000~6000分鐘
	3. `egs/voxforge/s5`，走`bash getdata.sh`佮`time bash -x run.sh`
		- 純CPU時間
			- `real    10081m51.386s`、`user    32927m9.961s`、`sys     294m11.191s`
4. 看[導覽教學](http://kaldi-asr.org/doc/tutorial.html)
   - 伊的例，語料愛錢，所以提第三步的`yesno`佮`vystadial_en`比較
   - `vystadial_en`的`data`資料夾，叫做`lang_prep`
5. 照[資料準備](http://kaldi-asr.org/doc/data_prep.html)
   - 一步一步做
6. 修改範例
   - [taiwanese](https://github.com/sih4sing5hong5/kaldi/tree/taiwanese/egs/taiwanese/s5c)
     - 自`swbd`改的
     - 參考`timit`佮`swbd`的`sgmm2`
   - `egs/voxforge/s5/`的`run.sh`上清氣，較好看
   - `iban` `sgmm2`的`rescore`佮`big lm`
     - 用細lm來`decode`才閣用大lm來`rescore`(15.84%)，不如直接用大lm來`decode`(15.32%)
   - `voxforge`有`mpe`
   - `nnet3`：`wsj`、`swbd`
   - `wsj/s5/local/run_sgmm2.sh` `quinphone`
   - 簡單瞭解各個做法：[2013_interspeech_dnn](http://www.danielpovey.com/files/2013_interspeech_dnn.pdf)

### 其他參考文章
* GPU對decoding較無效果
  * https://groups.google.com/d/msg/kaldi-help/cXUxiXDAJUs/fnFGFSTnBgAJ
  * https://groups.google.com/forum/#!topic/kaldi-help/Zujqc0ishQU
* jobs佮thread設定
  * https://groups.google.com/forum/#!msg/kaldi-help/kTDwa48u2PM/M5qMYGPVCwAJ
* globalphone model
  * https://groups.google.com/forum/#!msg/kaldi-help/ifUe6IuGdFc/PkF5j1atCwAJ
* rnnlm
  * https://groups.google.com/forum/#!topic/kaldi-help/018JjvRBz-M
  * https://groups.google.com/forum/#!msg/kaldi-help/csJrMoGwEpU/gZQDveHLCwAJ
* acwt參數
  * https://groups.google.com/forum/#!topic/kaldi-developers/IBhn9ndmjQI
* 入門文章
  * https://groups.google.com/forum/#!msg/kaldi-help/3LBSzmploC0/xDPK2vuXDgAJ
  * https://groups.google.com/d/msg/kaldi-help/3LBSzmploC0/ff35yEUqEgAJ
* lattice
  * https://groups.google.com/forum/#!topic/kaldi-help/cXX7y3Hvf3w
  * https://groups.google.com/forum/#!topic/kaldi-help/QqUQoX816GE
  * https://groups.google.com/forum/#!topic/kaldi-help/UiVD5WPA8fI
* sil
  * https://groups.google.com/forum/#!msg/kaldi-help/r4pgYLcHfUA/bCz1nyqcDAAJ
* 錄音相關
  * https://groups.google.com/forum/#!msg/kaldi-help/gBRw7svAQHs/39MuJdu3AAAJ
* 手機錄音
  * https://groups.google.com/forum/m/#!msg/kaldi-help/gBRw7svAQHs/YAHKN-PhAAAJ
* 猶未整理
   - https://sourceforge.net/p/kaldi/discussion/1355348/thread/c99fe7a6/?limit=25
   - http://vpanayotov.blogspot.tw/2012/06/kaldi-decoding-graph-construction.html
   - https://sourceforge.net/p/kaldi/discussion/1355347/thread/33098413/?page=0
   - https://sourceforge.net/p/kaldi/discussion/1355348/thread/476965d5/
   

### 訓練語料準備
2016/11/12唐鳳的建議

#### 音檔編碼格式

* flac
* opus
  * watson IBM在用
* aac

訊號完整度（對辨識的影響）：`flac`>`opus`>`aac`

#### 錄音流程
1. 準備萬字表，而且準備做一段一段。一段的長度，是一般人唸了需要啉茶歇睏的長度
2. 揣發音人，一直予伊唸，一段存一个音檔
3. 轉去實驗室，共音檔佮萬字表alignment

#### 補錄語料
若是拄著辨識錯誤，袂共這个音檔當做訓練語料，會分析是佗位錯誤，若是是腔口的問題，就去錄彼腔口的聲音


### 針測信號（Voice activity detection, VAD）
切語料時會需要。[查資料](https://github.com/sih4sing5hong5/tai5-uan5_gian5-gi2_kang1-ku7/issues/287#issuecomment-262528810)的結果，是用praat就可以得著誠好的結果矣

1. 用praat GUI程式，`minimun pitch`從100Hz調整到60Hz，其他用預設餐數
2. praat script，需要參考[Sound: To TextGrid (silences)...](http://www.fon.hum.uva.nl/praat/manual/Sound__To_TextGrid__silences____.html)佮相像的[script](http://www.helsinki.fi/%7Elennes/praat-scripts/public/mark_pauses.praat)

### 訓練語料過濾
若是訓練語料無夠清氣，會當用`steps/cleanup/clean_and_segment_data.sh`

#### 會切音檔
```
tong0000292-0002921無註明-ku0002921 因-為｜in1-ui7 原-地｜guan5-te7 有｜u7 水｜tsui2 go2｜go2 到｜kah8 水-源｜tsui2-guan5
tong0000292-0002921無註明-ku0002921-1 因-為｜in1-ui7 原-地｜guan5-te7 有｜u7
tong0000292-0002921無註明-ku0002921-2 水-源｜tsui2-guan5

tong0000292-0002921無註明-ku0002921 tong0000292 7082.32000000001 7085.32800000001
tong0000292-0002921無註明-ku0002921-1 tong0000292 7082.32 7083.63
tong0000292-0002921無註明-ku0002921-2 tong0000292 7084.4 7085.33
```

雖然原本的音檔就誠好矣，毋過新的兩个音檔切了閣袂bai2

#### 調時間
```
tong0016578-0000000無註明-ku0000000 tong0016578 0 2.115918367346939
tong0016578-0000000無註明-ku0000000-1 tong0016578 0.74 1.905
```
- 毋過會切毋著 https://github.com/sih4sing5hong5/tai5-uan5_gian5-gi2_hok8-bu7/issues/134

#### 加`<UNK>`
```
tong0000004-0000002朝森-ku0000604 講-了｜kong2-liau2 誠-好｜tsiann5-ho2
tong0000004-0000002朝森-ku0000604-1 <UNK> 講-了｜kong2-liau2 誠-好｜tsiann5-ho2

tong0000027-0000011阿婆-ku0000012 曷｜ah8 是｜si7 按-怎｜an2-nua2 今-仔-日｜kin1-a2-jit8 是｜si7 啥-物｜siann2-mih8 日-子｜jit8-tsi2 按-呢｜an2-ne1 tsiah10｜tsiah10 食｜tsiah8 好｜ho2
tong0000027-0000011阿婆-ku0000012-1 <UNK> 啥-物｜siann2-mih8 日-子｜jit8-tsi2 按-呢｜an2-ne1 tsiah10｜tsiah10 食｜tsiah8 好｜ho2
```
`tong0000004-0000002朝森-ku0000604`頭前有華語`學長`

#### 綜合三个
```
tong0000292-0003393無註明-ku0003393 佇｜ti7 茫-茫｜bang5-bang5 的｜e5 人｜lang5 先｜sing1 路-途｜loo7-too5
tong0000292-0003393無註明-ku0003393-1 佇｜ti7 茫-茫｜bang5-bang5 的｜e5
tong0000292-0003393無註明-ku0003393-2 <UNK> 先｜sing1 路-途｜loo7-too5

tong0000292-0003393無註明-ku0003393 tong0000292 8147.24800000001 8150.0480000000
tong0000292-0003393無註明-ku0003393-1 tong0000292 8147.25 8148.62
tong0000292-0003393無註明-ku0003393-2 tong0000292 8148.88 8150.04
```
∵是`jin5`毋是`lang5`


### Taiwanese Study討論紀錄
這區是高明達老師、呂仁園老師、呂道誠學長佮薛丞宏的討論紀錄

#### 臺語文本格式
臺語有`漢字`佮`臺羅`兩種表示法，華語免標注音，是因為有漢字就有法度標注音。

羅馬字大部份攏有標聲調，而且是標本調，臺語的漢字佮羅馬字才整合無偌久，實務上有需要兩个做伙做

```
伊｜i1 攏-是｜long2-si7 恬-恬-仔｜tiam7-tiam7-a2 搰-力｜kut4-lat4 去-做｜khi3-tso7
```

我佇`lexcicon.txt`辭典內底共in拆開
```
伊｜i1 ʔ- i1
攏-是｜long2-si7 l- o2 ŋ2 s- i7
恬-恬-仔｜tiam7-tiam7-a2 t- i7 a7 m7 t- i7 a7 m7 ʔ- a2
…
```

嘛因為kaldi有共辭典獨立出來，變調只要改`lexcicon.txt`就好
```
伊｜i1 ʔ- i1 #無變調
伊｜i1 ʔ- i7 #變調
攏-是｜long2-si7 l- o1 ŋ1 s- i7 #頭字變，尾字無變
攏-是｜long2-si7 l- o1 ŋ1 s- i3 #頭字變，尾字變調
```

lm的文本，大部份的原始來源攏是漢羅
轉做`攏-是｜long2-si7`這種分詞格式是實務上較會通

#### 語音分析
`pang`佇辭典內底，會當照無仝的單位切

1. 聲韻會當拆成`p`、`ang`
2. 音素會拆成`p`、`a`、`ng`

華語之前Microsoft好像有用音素做，但近幾年大家都是用聲韻


#### 語言模型分析
##### Perplexity
詳細數字要看採用的文字語料中【相異】的語言單位之數量。

```
辨識單位 |Ngram| Perplexity 
---------|-----| ---------- 
文(Ch) | 0g | 3426 
文(Ch) | 7g | 37 
音(Ts) | 0g | 2441 
音(Ts) | 7g | 45
```

以上是TwESC01 (朗讀140篇)10萬字左右做出來的結果。

其中 3426 恰好是10萬字中，相異的漢羅字數；2441恰好是相異的帶聲調音節數。

##### 案例1
試perplexity的結果是這樣：
```
$ ngram -lm data/local/lm/語言模型.lm -ppl text_tshi3.txt
data/local/lm/語言模型.lm: line 7: warning: non-zero probability for <unk> in closed-vocabulary LM
file text_tshi3.txt: 277 sentences, 1135 words, 0 OOVs
0 zeroprobs, logprob= -5321.24 ppl= 5869.24 ppl1= 48788.2
```
通常英文的`ppl`在`100`左右，華語大約在`200`。`5000`太高了

### 分析辨識問題
愛判斷是聲學模型的問題無，所以先共語言模型的影響提掉

#### 實驗1
通常中文`inside 3 gram 語言模型`配合`outside的音檔`，
`Character error rate`大約在5%。

#### 實驗2
用 去聲調的音節 做成 1gram 的語言模型，
看看辨識結果如何，
應該正確率要差不多 50-60之間。


## HTK
臺灣言語工具捌共[HTK](http://htk.eng.cam.ac.uk/)的功能包起來，毋過這馬無按算閣維護辨識的部份矣，請看[原因](https://github.com/sih4sing5hong5/tai5-uan5_gian5-gi2_hok8-bu7/pull/113)。

### 套件準備
```bash
sudo apt-get install -y libc6-dev-i386 linux-libc-dev gcc-multilib libx11-dev libx11-dev:i386
```

### 安裝
執行`python`，而且輸入
```python3
from 臺灣言語工具.語音辨識.HTK工具.安裝HTK語音辨識程式 import 安裝HTK語音辨識程式
安裝HTK語音辨識程式.安裝htk()
```

### 標文本的時間
若是有音檔佮對應的文本音標，會使標出逐個語詞佇音檔的時間
```python3
對齊標仔目錄 = HTK辨識模型訓練.加短恬閣對齊(
    音檔目錄, 標仔目錄, 音節聲韻對照檔, 模型暫存目錄
)
```

#### 標仔格式說明
以`試驗/語音辨識/語音語料/labels`的資料為例
標仔`刀石`應該生做，其中`sil`表示音檔前後有一段空白無聲
```
sil
to
tsioh
sil
```

#### 音檔格式說明
以`試驗/語音辨識/語音語料/wav`的資料為例
愛準備對應標仔檔名的wav檔案

#### 音節聲韻對照檔格式說明
這個檔案的目的是予HTK會當用聲韻，閣較細的單位來辨識，增加準度

以`試驗/語音辨識/語音語料/聲韻對照.dict`的資料為例
```
a	ʔ a
ah	ʔ aʔ
ai	ʔ ai
aih	ʔ aiʔ
……
```
第一逝代表`a`會當拆做`ʔ`佮`a`
第二逝代表`ah`會當拆做`ʔ`佮`aʔ`
以此類推…

#### 輸出標仔格式
走面頂的程式了，會得著有標時間的標仔檔
```
0 2100000 sil
2100000 5500000 to
5500000 9300000 tsioh
9300000 11100000 sil
```

### 辨識任意音檔
```python3
from 臺灣言語工具.語音辨識.HTK工具.HTK辨識模型訓練 import HTK辨識模型訓練
from 臺灣言語工具.語音辨識.HTK工具.HTK語料處理 import HTK語料處理
from 臺灣言語工具.語音辨識.HTK工具.HTK辨識模型 import HTK辨識模型
# 訓練模型
三連音辨識模型 = HTK辨識模型訓練.訓練三連音辨識模型(
    音檔目錄, 標仔目錄, 音節聲韻對照檔, 模型暫存目錄
)
# 辨識音檔
特徵檔 = HTK語料處理.產生特徵檔(音檔所在, 暫存目錄)
三連音辨識模型.辨識音節(特徵檔, 結果暫存目錄, 3)
# 儲存模型、載入
三連音辨識模型.存資料佇(模型目錄)
三連音辨識模型 = HTK辨識模型(模型目錄)
```

### HTK原理

HTK是揣出語音佮音標的對應，
共語音轉做一个一个MFCC聲學特徵，
主要是用高斯混合模型去判斷是佇一个音標。

用隱性馬可夫模型（HMM）來模擬語音狀態的變化，
解決語音訊號連續閣無固定長度的問題。

#### 模型訓練流程
##### 一般模型
1. 建立初步模型
  * 假設逐個音的GMM高斯混合模型參數攏仝款
2. 模型重估
  * 用[EM算法](https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E6%9C%9F%E6%9C%9B%E7%AE%97%E6%B3%95)切音，而且統計逐個音的參數

##### 加短恬模型
有的音節中央可能無聲音，所以佇中央加`sp短恬`，增加辨識度

1. 建立一般模型
2. 佇音節標仔中央加`sp短恬`
3. 模型佮標仔類檔嘛加`sp短恬`
4. 模型重估
5. 用模型切音，若`sp短恬`傷短，代表音節中央有聲，所以提掉
6. 模型重估

##### 三連音模型
原本的模型攏是考慮`音`本身（mono-phone）的參數，
若是為著提懸辨識度，考慮音的前後音（Context-Sensitive），
`前-音-後`三連音（tri-phone）。
毋過按呢模型會上濟，
就會用決策樹，合併相倚的高斯模型。

1. 建立加短恬模型
2. 模型佮標仔轉做三連音
3. 模型重估
4. 用決策樹，共相倚的三連音，因的高斯模型縛做伙
  * 合併相像的模型，按呢樣本數較濟，訓練較準
5. 模型閣重估

##### 其他
佇`HTK辨識模型訓練.py`內底，會當看著訓練模型了，
閣會`加混合數`，是予高斯混合模型有較濟的平均點，增加辨識度。

## 相關工具
* [EasyAlign](http://latlcui.unige.ch/phonetique/easyalign.php)
	* 用praat做的對齊工具